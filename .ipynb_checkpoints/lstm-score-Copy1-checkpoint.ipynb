{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from models import *\n",
    "from main import *\n",
    "from configs import cfg\n",
    "from nltk.translate import bleu_score as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['batch_size'] = 1\n",
    "cfg['gen_temp'] = 0.01\n",
    "model = load_model(BeerLstmMind, 'models2/e6b6700.pt', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('/datasets/home/32/032/sugao/CSE190/pa4/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('/datasets/cs190f-public/Beeradvocate_TestOriginal.csv')\n",
    "df.dropna(subset=['review/overall', 'beer/style'],how='any',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i_batch in range(0, len(test_data), 10):\n",
    "    all_txt = generate(model, test_data[i_batch:i_batch + 10], cfg, True)\n",
    "    if (i_batch + 1) % 3000 == 0:\n",
    "        score = calc_score(df, np.arange(i_batch, i_batch + 10), all_txt)\n",
    "        scores.append(score)\n",
    "        print(i_batch, score)\n",
    "    del all_txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40560280078928845"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('/datasets/home/32/032/sugao/CSE190/pa4/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = np.load('./val2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('/datasets/cs190f-public/BeerAdvocateDataset/BeerAdvocate_Train.csv')\n",
    "df.dropna(subset=['review/text'],how='any',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4007407856873235\n",
      "366.21500409953296\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "n = 10\n",
    "start = time.perf_counter()\n",
    "for i_batch in range(1000, 2000, n):\n",
    "    all_txt = generate(model, training_data[valid_indices[i_batch:i_batch + n]], cfg, False)\n",
    "    score = calc_score(df, valid_indices[i_batch:i_batch + n], all_txt)\n",
    "    del all_txt\n",
    "    scores.append(score)\n",
    "end = time.perf_counter()\n",
    "print(np.mean(scores))\n",
    "print((end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "n = 10\n",
    "start = time.perf_counter()\n",
    "for i_batch in range(1000, 2000, n):\n",
    "    all_txt = generate(model, training_data[valid_indices[i_batch:i_batch + n]], cfg, False)\n",
    "    score = calc_score(df, valid_indices[i_batch:i_batch + n], all_txt)\n",
    "    del all_txt\n",
    "    scores.append(score)\n",
    "end = time.perf_counter()\n",
    "print(np.mean(scores))\n",
    "print((end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
