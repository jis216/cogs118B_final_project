{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_dict(dictionary, path ):\n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(dictionary, fp)\n",
    "\n",
    "def load_dict(path ):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('glove.840B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove = {key: val.values for key, val in df.T.items()}\n",
    "\n",
    "save_dict(glove,'glove.840B.300d.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = load_dict('glove.840B.300d.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.082752 ,  0.67204  , -0.14987  , -0.064983 ,  0.056491 ,\n",
       "        0.40228  ,  0.0027747, -0.3311   , -0.30691  ,  2.0817   ,\n",
       "        0.031819 ,  0.013643 ,  0.30265  ,  0.0071297, -0.5819   ,\n",
       "       -0.2774   , -0.062254 ,  1.1451   , -0.24232  ,  0.1235   ,\n",
       "       -0.12243  ,  0.33152  , -0.006162 , -0.30541  , -0.13057  ,\n",
       "       -0.054601 ,  0.037083 , -0.070552 ,  0.5893   , -0.30385  ,\n",
       "        0.2898   , -0.14653  , -0.27052  ,  0.37161  ,  0.32031  ,\n",
       "       -0.29125  ,  0.0052483, -0.13212  , -0.052736 ,  0.087349 ,\n",
       "       -0.26668  , -0.16897  ,  0.015162 , -0.0083746, -0.14871  ,\n",
       "        0.23413  , -0.20719  , -0.091386 ,  0.40075  , -0.17223  ,\n",
       "        0.18145  ,  0.37586  , -0.28682  ,  0.37289  , -0.16185  ,\n",
       "        0.18008  ,  0.3032   , -0.13216  ,  0.18352  ,  0.095759 ,\n",
       "        0.094916 ,  0.008289 ,  0.11761  ,  0.34046  ,  0.03677  ,\n",
       "       -0.29077  ,  0.058303 , -0.027814 ,  0.082941 ,  0.1862   ,\n",
       "       -0.031494 ,  0.27985  , -0.074412 , -0.13762  , -0.21866  ,\n",
       "        0.18138  ,  0.040855 , -0.113    ,  0.24107  ,  0.3657   ,\n",
       "       -0.27525  , -0.05684  ,  0.34872  ,  0.011884 ,  0.14517  ,\n",
       "       -0.71395  ,  0.48497  ,  0.14807  ,  0.62287  ,  0.20599  ,\n",
       "        0.58379  , -0.13438  ,  0.40207  ,  0.18311  ,  0.28021  ,\n",
       "       -0.42349  , -0.25626  ,  0.17715  , -0.54095  ,  0.16596  ,\n",
       "       -0.036058 ,  0.08499  , -0.64989  ,  0.075549 , -0.28831  ,\n",
       "        0.40626  , -0.2802   ,  0.094062 ,  0.32406  ,  0.28437  ,\n",
       "       -0.26341  ,  0.11553  ,  0.071918 , -0.47215  , -0.18366  ,\n",
       "       -0.34709  ,  0.29964  , -0.66514  ,  0.002516 , -0.42333  ,\n",
       "        0.27512  ,  0.36012  ,  0.16311  ,  0.23964  , -0.05923  ,\n",
       "        0.3261   ,  0.20559  ,  0.038677 , -0.045816 ,  0.089764 ,\n",
       "        0.43151  , -0.15954  ,  0.08532  , -0.26572  , -0.15001  ,\n",
       "        0.084286 , -0.16714  , -0.43004  ,  0.060807 ,  0.13121  ,\n",
       "       -0.24112  ,  0.66554  ,  0.4453   , -0.18019  , -0.13919  ,\n",
       "        0.56252  ,  0.21457  , -0.46443  , -0.012211 ,  0.029988 ,\n",
       "       -0.051094 , -0.20135  ,  0.80788  ,  0.47377  , -0.057647 ,\n",
       "        0.46216  ,  0.16084  , -0.20954  , -0.05452  ,  0.15572  ,\n",
       "       -0.13712  ,  0.12972  , -0.011936 , -0.003378 , -0.13595  ,\n",
       "       -0.080711 ,  0.20065  ,  0.054056 ,  0.046816 ,  0.059539 ,\n",
       "        0.046265 ,  0.17754  , -0.31094  ,  0.28119  , -0.24355  ,\n",
       "        0.085252 , -0.21011  , -0.19472  ,  0.0027297, -0.46341  ,\n",
       "        0.14789  , -0.31517  , -0.065939 ,  0.036106 ,  0.42903  ,\n",
       "       -0.33759  ,  0.16432  ,  0.32568  , -0.050392 , -0.054297 ,\n",
       "        0.24074  ,  0.41923  ,  0.13012  , -0.17167  , -0.37808  ,\n",
       "       -0.23089  , -0.019477 , -0.29291  , -0.30824  ,  0.30297  ,\n",
       "       -0.22659  ,  0.081574 , -0.18516  , -0.21408  ,  0.40616  ,\n",
       "       -0.28974  ,  0.074174 , -0.17795  ,  0.28595  , -0.039626 ,\n",
       "       -0.2339   , -0.36054  , -0.067503 , -0.091065 ,  0.23438  ,\n",
       "       -0.0041331,  0.003232 ,  0.0072134,  0.008697 ,  0.21614  ,\n",
       "        0.049904 ,  0.35582  ,  0.13748  ,  0.073361 ,  0.14166  ,\n",
       "        0.2412   , -0.013322 ,  0.15613  ,  0.083381 ,  0.088146 ,\n",
       "       -0.019357 ,  0.43795  ,  0.083961 ,  0.45309  , -0.50489  ,\n",
       "       -0.10865  , -0.2527   , -0.18251  ,  0.20441  ,  0.13319  ,\n",
       "        0.1294   ,  0.050594 , -0.15612  , -0.39543  ,  0.12538  ,\n",
       "        0.24881  , -0.1927   , -0.31847  , -0.12719  ,  0.4341   ,\n",
       "        0.31177  , -0.0040946, -0.2094   , -0.079961 ,  0.1161   ,\n",
       "       -0.050794 ,  0.015266 , -0.2803   , -0.12486  ,  0.23587  ,\n",
       "        0.2339   , -0.14023  ,  0.028462 ,  0.56923  , -0.1649   ,\n",
       "       -0.036429 ,  0.010051 , -0.17107  , -0.042608 ,  0.044965 ,\n",
       "       -0.4393   , -0.26137  ,  0.30088  , -0.060772 , -0.45312  ,\n",
       "       -0.19076  , -0.20288  ,  0.27694  , -0.060888 ,  0.11944  ,\n",
       "        0.62206  , -0.19343  ,  0.47849  , -0.30113  ,  0.059389 ,\n",
       "        0.074901 ,  0.061068 , -0.4662   ,  0.40054  , -0.19099  ,\n",
       "       -0.14331  ,  0.018267 , -0.18643  ,  0.20709  , -0.35598  ,\n",
       "        0.05338  , -0.050821 , -0.1918   , -0.37846  , -0.06589  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_dict[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import load_data\n",
    "train_path = './essay_dataset/training_set_rel3.tsv'\n",
    "train_df = load_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['essay_id','essay_set','essay','rater1_domain1','rater2_domain1','domain1_score']]\n",
    "set_3 = train_df[train_df.essay_set == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Dear local newspaper, I think effects computer...\n",
       "1        Dear @CAPS1 @CAPS2, I believe that using compu...\n",
       "2        Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...\n",
       "3        Dear Local Newspaper, @CAPS1 I have found that...\n",
       "4        Dear @LOCATION1, I know having computers has a...\n",
       "5        Dear @LOCATION1, I think that computers have a...\n",
       "6        Did you know that more and more people these d...\n",
       "7        @PERCENT1 of people agree that computers make ...\n",
       "8        Dear reader, @ORGANIZATION1 has had a dramatic...\n",
       "9        In the @LOCATION1 we have the technology of a ...\n",
       "10       Dear @LOCATION1, @CAPS1 people acknowledge the...\n",
       "11       Dear @CAPS1 @CAPS2 I feel that computers do ta...\n",
       "12       Dear local newspaper I raed ur argument on the...\n",
       "13       My three detaileds for this news paper article...\n",
       "14       Dear, In this world today we should have every...\n",
       "15       Dear @ORGANIZATION1, The computer blinked to l...\n",
       "16       Dear Local Newspaper, I belive that computers ...\n",
       "17       Dear Local Newspaper, I must admit that the ex...\n",
       "18       I aegre waf the evansmant ov tnachnolage. The ...\n",
       "19       Well computers can be a good or a bad thing. I...\n",
       "20       Dear @CAPS1 of the @CAPS2 @CAPS3 daily, I am w...\n",
       "21       Dear local Newspaper @CAPS1 a take all your co...\n",
       "22       Dear local newspaper, @CAPS1 you ever see a ch...\n",
       "23       Dear local newspaper, I've heard that not many...\n",
       "24       Dear @CAPS1, @CAPS2 off, I beileve that comput...\n",
       "25       Do you think that computers are useless? Or do...\n",
       "26       Computers a good because you can get infermati...\n",
       "27       Dear Newspaper, Computers are high tec and hav...\n",
       "28       Dear local newspaper, @CAPS1 people throughout...\n",
       "29       Dear Newspaper People, I think that computers ...\n",
       "                               ...                        \n",
       "12946     We all understand the benefits of laughter. L...\n",
       "12947          It was midsummer, and i could feel the c...\n",
       "12948     Have you ever experienced a time with your fr...\n",
       "12949     I woke up just like any other day happy yet l...\n",
       "12950     Laughter is an important part of my life, eit...\n",
       "12951     I sat at the table, speechless, as they told ...\n",
       "12952     As I remember back, it was @DATE1. It was a h...\n",
       "12953     Those eyes, it was like I was looking out int...\n",
       "12954    Some say that laugh is the common language bet...\n",
       "12955     Laughter is an integral element to many situa...\n",
       "12956    One time I was at my friend @PERSON1's house, ...\n",
       "12957     LAUGHTER @CAPS1 knows that laughter is a heal...\n",
       "12958    One thing that people in the world love to do ...\n",
       "12959     Laughter, to me, is an important aspect of my...\n",
       "12960     People always say that the worst parts of lif...\n",
       "12961     Why is it that people can look back at someth...\n",
       "12962     Before my best friend moved away, we would st...\n",
       "12963                                  @ORGANIZATION1  ...\n",
       "12964     Morose and somnolent, I woke up. I woke up to...\n",
       "12965     A while back my mom had decided to send me to...\n",
       "12966                                I dont like computers\n",
       "12967     Everyone knows how important a laugh can be. ...\n",
       "12968     Laughter is an important part of my family. W...\n",
       "12969     laughter is an important part of any kind of ...\n",
       "12970    Sometime ago on a hot @DATE1 day my @NUM1 ,@PE...\n",
       "12971     In most stories mothers and daughters are eit...\n",
       "12972     I never understood the meaning laughter is th...\n",
       "12973    When you laugh, is @CAPS5 out of habit, or is ...\n",
       "12974                                   Trippin' on fen...\n",
       "12975     Many people believe that laughter can improve...\n",
       "Name: essay, Length: 12976, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "dict_set = set()\n",
    "for e in train_df.essay:\n",
    "    r = ''.join([c for c in e.lower() if not c in punctuation])\n",
    "    dict_set = dict_set.union(r.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [0.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [0.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [0.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [0.0, 1.0, 1.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = np.zeros((5,1))\n",
    "essays = np.ones((5,4))\n",
    "b = np.hstack((scores,essays))\n",
    "b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 2, 3],\n",
       "       [7, 8, 9, 4, 5, 6]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack(([[1,1,1],[7,8,9]], [[1,2,3],[4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5], [5], [5], [1, 2, 3], [1, 2, 3], [1, 2, 3]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[5]]*3\n",
    "b = [[1,2,3],[1,2,3],[1,2,3]]\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(1,4).reshape((4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0]+[1]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5], [7, 8, 91, 10, 11], [-1, 0, 0, 0, 0], [-1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos = [0] * 5\n",
    "eos[0] = -1\n",
    "a = [[1,2,3,4,5],[7,8,91,10,11]]\n",
    "a += 2 * [eos]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "def load_data(fname):\n",
    "    # TODO: From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    df = pd.read_table(fname, encoding = \"ISO-8859-1\")\n",
    "    return df\n",
    "def process_train_data(text, score, word_dict,device):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).    \n",
    "    lowered = ''.join([(' '+c+' ') if c in punctuation else c for c in text.lower() ])\n",
    "    sequence = lowered.split()\n",
    "        \n",
    "    sequence_feats = torch.zeros(len(sequence)+2, 302, dtype=torch.float, device=device)\n",
    "    sequence_feats[:,0] = float(score)\n",
    "    \n",
    "    # SOS is [-1, 300 * 0]\n",
    "    sequence_feats[0,1] = -1\n",
    "    \n",
    "    for ind, word in enumerate(sequence):\n",
    "        if word not in word_dict:\n",
    "            word = ''.join([c for c in word if not c.isdigit()])\n",
    "        if word not in word_dict:\n",
    "            sequence_feats[ind+1, 1] = 1\n",
    "            for i,c in enumerate(word):\n",
    "                sequence_feats[2 + ord(c)] += (i+1) * 0.05 - 0.5\n",
    "        else:\n",
    "            sequence_feats[ind+1, 1] = 0\n",
    "            sequence_feats[ind+1, 2:] = torch.FloatTensor(word_dict[word].tolist(),device=device)\n",
    "        \n",
    "    # EOS is [-1, 300 * 1]\n",
    "    sequence_feats[-1,1:] = -1\n",
    "    \n",
    "    #print(np.asarray(essay_feats)[:,0])\n",
    "    #print(essay_feats[len(essay_feats)-1])\n",
    "    \n",
    "    return sequence_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_fname = './essay_dataset/training_set_rel3.tsv'\n",
    "\n",
    "train_data = load_data(train_data_fname) \n",
    "train_data.dropna(subset=['domain1_score', 'essay'],how='any',inplace = True)\n",
    "        \n",
    "scores = train_data['domain1_score']\n",
    "essays = train_data['essay']\n",
    "\n",
    "glove_dict = load_dict('glove.840B.300d.pkl')\n",
    "\n",
    "#limit = float('inf')\n",
    "#if len(sys.argv) > 2:\n",
    "#    limit = int(sys.argv[2])\n",
    "limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "tensor([[ 8.0000, -1.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 8.0000,  0.0000, -0.2200,  ...,  0.0854, -0.6781, -0.2568],\n",
      "        [ 8.0000,  0.0000,  0.2165,  ..., -0.9390, -0.1228,  0.6084],\n",
      "        ...,\n",
      "        [ 8.0000,  0.0000,  0.3519,  ...,  0.3619, -0.1327, -0.0909],\n",
      "        [ 8.0000,  0.0000,  0.0120,  ...,  0.1387, -0.3605, -0.0350],\n",
      "        [ 8.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, es in enumerate(essays):\n",
    "    print(type(scores[index]))\n",
    "    arr = process_train_data(es, scores[index],glove_dict, 'cuda')\n",
    "    res= arr\n",
    "    if (index + 1) % 5000 == 0:\n",
    "        print(index + 1)\n",
    "    if index + 1 == limit:\n",
    "        break\n",
    "    break\n",
    "    #print(res)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-203cdef5a0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "load = np.load('train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 302)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(load[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.       -1.        0.       ...  0.        0.        0.      ]\n",
      " [ 8.        0.       -0.22003  ...  0.085375 -0.67812  -0.25684 ]\n",
      " [ 8.        0.        0.21647  ... -0.93896  -0.12281   0.60839 ]\n",
      " ...\n",
      " [ 8.        0.        0.35185  ...  0.36189  -0.13267  -0.090906]\n",
      " [ 8.        0.        0.012001 ...  0.13871  -0.36049  -0.035   ]\n",
      " [ 8.       -1.        1.       ...  1.        1.        1.      ]]\n"
     ]
    }
   ],
   "source": [
    "print(load[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "train = torch.zeros(3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 =[[0,0,1],[2,2,2],[6,6,6]]\n",
    "seq2 = [[4,5,6],[7,3,9],[6,7,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  1.],\n",
       "         [ 2.,  2.,  2.],\n",
       "         [ 6.,  6.,  6.]],\n",
       "\n",
       "        [[ 4.,  5.,  6.],\n",
       "         [ 7.,  3.,  9.],\n",
       "         [ 6.,  7.,  9.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [seq1,seq2]\n",
    "lens = [[3],[2]]\n",
    "train[[0,1]] = torch.FloatTensor(seqs)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.zeros(3,1)\n",
    "label[[0,1,2],0] = torch.FloatTensor([0,1,2])\n",
    "label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0] * 10\n",
    "[a]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "n_indices = torch.zeros((self.batch_size, 1), dtype=torch.long, device=self.device)\n",
    "batch_arange = torch.arange(self.batch_size, dtype=torch.long, device=self.device)\n",
    "n_indices[batch_arange,0] = batch_arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "label = torch.zeros(3, 1, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_arange = torch.arange(3,dtype=torch.long)\n",
    "label[batch_arange, 0] = torch.tensor([0.1,0.5,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "label = torch.zeros(3, 1, dtype=torch.float, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
