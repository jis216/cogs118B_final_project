{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from models import *\n",
    "from main import *\n",
    "from configs import cfg\n",
    "from nltk.translate import bleu_score as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['gen_temp'] = 0.4\n",
    "fname = 'reviews/reviews_tau_0.01.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('/datasets/home/32/032/sugao/CSE190/pa4/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('/datasets/cs190f-public/Beeradvocate_TestOriginal.csv')\n",
    "df.dropna(subset=['review/overall', 'beer/style'],how='any',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323 0.35014149298400593\n",
      "5323 0.3569402682808938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8323 0.049190657415415534\n",
      "11323 0.3327264426355143\n",
      "14323 0.3445337429661781\n",
      "17323 0.3423328016153426\n",
      "20323 0.3560839540547193\n",
      "23323 0.05116451188206174\n",
      "26323 0.35732247277771156\n",
      "29323 0.04318696603024291\n",
      "32323 0.04534597509287905\n",
      "35323 0.05598889346906769\n",
      "38323 0.05652028595774142\n",
      "41323 0.2891223476078993\n",
      "44323 0.37026513147924517\n",
      "47323 0.058389421830886384\n",
      "50323 0.05471650713289312\n",
      "53323 0.05954139367282448\n",
      "56323 0.3430342691088023\n",
      "59323 0.3471104658966625\n",
      "62323 0.05140052849373915\n",
      "65323 0.0627311745502811\n",
      "68323 0.3491210779474666\n",
      "71323 0.06224602640626996\n",
      "74323 0.046087405779838025\n",
      "77323 0.3320956431498245\n",
      "80323 0.04928484530419629\n",
      "83323 0.3427749977597686\n",
      "86323 0.04902640061398098\n",
      "89323 0.052234661804056205\n",
      "92323 0.33857776844093024\n",
      "95323 0.051859268362104236\n",
      "98323 0.35910739460933266\n",
      "101323 0.06275020421729878\n",
      "104323 0.32132194483628757\n",
      "107323 0.05744890569988377\n",
      "110323 0.0628265298466463\n",
      "113323 0.3380571025689078\n",
      "116323 0.05236586512671986\n",
      "119323 0.34449697505113935\n",
      "122323 0.36802533107073737\n",
      "125323 0.3343341309253412\n",
      "128323 0.061220298442529276\n",
      "131323 0.3396138366371985\n",
      "134323 0.3353525727555528\n",
      "137323 0.35709290473582317\n",
      "140323 0.048515735904793966\n",
      "143323 0.050865785510145124\n",
      "146323 0.04909669509812079\n",
      "149323 0.059617226853784316\n",
      "152323 0.35245708781352136\n",
      "155323 0.3604460690530854\n",
      "158323 0.04995307903578418\n",
      "161323 0.06002662222476649\n",
      "164323 0.3487805588485148\n",
      "167323 0.04955816206248733\n",
      "170323 0.05365260054468838\n",
      "173323 0.05049108176568158\n",
      "176323 0.04937889088952659\n",
      "179323 0.04593095510865411\n",
      "182323 0.33864956947739977\n",
      "185323 0.05354163519087383\n",
      "188323 0.3444578565613189\n",
      "191323 0.05827816525608133\n",
      "194323 0.33276812005254164\n",
      "197323 0.059363540553906864\n",
      "200323 0.06638722671881578\n",
      "203323 0.05206974759620907\n",
      "206323 0.35147435285718986\n",
      "209323 0.0512113268925249\n",
      "212323 0.04908865368171941\n",
      "215323 0.06149749268386924\n",
      "218323 0.3446810111096426\n",
      "221323 0.36529106137440537\n",
      "224323 0.32706269837420826\n",
      "227323 0.3423328016153426\n",
      "230323 0.36051187390640704\n",
      "233323 0.3583949970924514\n",
      "236323 0.3447471675514958\n",
      "239323 0.34277992711440236\n",
      "242323 0.05106435239772473\n",
      "245323 0.050252569388620105\n",
      "248323 0.04868339415596992\n",
      "251323 0.3521856535823236\n",
      "254323 0.3419617598396055\n",
      "257323 0.05222612598313697\n",
      "260323 0.05222741673063592\n",
      "263323 0.34756076863856084\n",
      "266323 0.051743432775452576\n",
      "269323 0.05923617877029041\n",
      "272323 0.0530164010886982\n",
      "275323 0.051094360807995974\n",
      "278323 0.34254371707835074\n",
      "281323 0.061846082200194004\n",
      "284323 0.061220806224277814\n",
      "287323 0.04977374584271374\n",
      "290323 0.0669002907586951\n",
      "293323 0.05093068309679857\n",
      "296323 0.05931286721047339\n",
      "299323 0.04821566242203049\n",
      "302323 0.04767139200111709\n",
      "305323 0.34711470042288156\n",
      "308323 0.05118087389689143\n",
      "311323 0.3428265494461317\n",
      "314323 0.3400284347699309\n"
     ]
    }
   ],
   "source": [
    "N = 3000\n",
    "start = len(df) % N\n",
    "cfg['batch_size'] = start\n",
    "model = load_model(BeerLstmMind, 'models2/e6b6700.pt', cfg)\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_txt = generate(model, test_data[0:start], cfg)\n",
    "    li = tensor2strlist(all_txt)\n",
    "    save_to_file(li, fname)\n",
    "\n",
    "cfg['batch_size'] = N\n",
    "model = load_model(BeerLstmMind, 'models2/e6b6700.pt', cfg)\n",
    "scores = []\n",
    "for i_batch in range(start, len(test_data), N):\n",
    "    with torch.no_grad():\n",
    "        all_txt = generate(model, test_data[i_batch:i_batch + N], cfg)\n",
    "        li = tensor2strlist(all_txt)        \n",
    "        score = calc_score(df, [x for x in range(i_batch, i_batch + 10)], li[0:10])\n",
    "        scores.append(score)\n",
    "        save_to_file(li, fname)\n",
    "        print(i_batch, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm-0.4 score median: 0.357\n",
    "# lstm-10 score median: 0\n",
    "# lstm-0.01 score median: 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061846082200194004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('/datasets/home/32/032/sugao/CSE190/pa4/train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = np.load('./val2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('/datasets/cs190f-public/BeerAdvocateDataset/BeerAdvocate_Train.csv')\n",
    "df.dropna(subset=['review/text'],how='any',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3532865912153181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056389223433255864\n",
      "0.361630984956203\n",
      "0.36425229529277364\n",
      "0.050643286536365184\n",
      "0.3589527138782376\n",
      "0.05489942350642204\n",
      "0.3756654947913578\n",
      "0.05719577280666564\n",
      "0.3718277547244044\n",
      "0.3530207954726666\n",
      "0.3676360869459134\n",
      "0.37461190706849723\n",
      "0.3692744729379982\n",
      "0.34308199709261133\n",
      "0.3614311636650761\n",
      "0.3588518717819272\n",
      "0.054064528469959364\n",
      "0.3609970982339188\n",
      "0.06685322498291954\n",
      "0.3594858081586778\n",
      "0.3563228886010494\n",
      "0.35363976006120196\n",
      "0.05394260717474201\n",
      "0.05644577711975125\n",
      "0.363699800531504\n",
      "0.34841842048516436\n",
      "0.05568017176727743\n",
      "0.34791594751284466\n",
      "0.3566325206249314\n",
      "0.054786606086544\n",
      "0.334813695420013\n",
      "0.36675589482044507\n",
      "0.37126875376323043\n",
      "0.36984386441868206\n",
      "0.3671103107900289\n",
      "0.36458256175774184\n",
      "0.3779644730092272\n",
      "0.36146855374095677\n",
      "0.34944336687845956\n",
      "0.36178446923218993\n",
      "0.3654154756905824\n",
      "0.05454458676725678\n",
      "0.359531304053806\n",
      "0.3735942070746957\n",
      "0.3784605555481003\n",
      "0.3728052949625663\n",
      "0.3518129698290836\n",
      "0.05455734387771074\n",
      "0.3624516018258833\n",
      "0.05372058414627142\n",
      "0.35983445157892197\n",
      "0.36517224147717864\n",
      "0.37515109035789956\n",
      "0.3700414022461426\n",
      "0.058344823927322736\n",
      "0.3655552228545123\n",
      "0.3610795765139213\n",
      "0.054954150702006134\n",
      "0.34132232937691886\n",
      "0.3607215127026264\n",
      "0.3478522558035378\n",
      "0.35412718754274375\n",
      "0.35531252918729994\n",
      "0.05538496803856656\n",
      "0.35435987929891455\n",
      "0.3622285408538391\n",
      "0.050980169584253415\n",
      "0.3591281980244561\n",
      "0.3603814977026143\n",
      "0.3581439285524371\n",
      "0.05607602463517759\n",
      "0.3513602976267067\n",
      "0.05572115852797888\n",
      "0.36640078790013564\n",
      "0.35959445895712433\n",
      "0.3495274586585512\n",
      "0.36725200597695773\n",
      "0.3625410187814518\n",
      "0.36821398145189993\n",
      "0.38443020351745877\n",
      "0.3712386569917533\n",
      "0.366825102512517\n",
      "0.07270280940481137\n",
      "0.35413493163316734\n",
      "0.35420084228697424\n",
      "0.35970149960663517\n",
      "0.362362295030433\n",
      "0.38860429884686687\n",
      "0.36687256031834997\n",
      "0.06785475417319232\n",
      "0.35601242970561514\n",
      "0.05638253631022922\n",
      "0.35658882904424943\n",
      "0.05697497843540254\n",
      "0.3482810224615455\n",
      "0.3312669925098738\n",
      "0.3546202086177164\n",
      "0.05447870726806009\n",
      "0.37030874118190543\n",
      "0.35849790016718214\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "n = 10\n",
    "cfg['batch_size'] = n\n",
    "model = load_model(BeerLstmMind, 'models2/e6b6700.pt', cfg)\n",
    "for i_batch in range(0, 1000, n):\n",
    "    meta = np.empty((n, 2))\n",
    "    data = training_data[valid_indices[i_batch:i_batch + n]]\n",
    "    for j in range(n):\n",
    "        meta[j, 0] = data[j][0]\n",
    "        meta[j, 1] = data[j][1]\n",
    "        \n",
    "    all_txt = generate(model, meta, cfg)\n",
    "    li = tensor2strlist(all_txt)\n",
    "    score = calc_score(df, valid_indices[i_batch:i_batch + n], li)\n",
    "    scores.append(score)\n",
    "    print(score)\n",
    "\n",
    "print(np.median(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
