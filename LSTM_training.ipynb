{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from preprocess import load_training_set, load_validation_set, load_dict, process_scores\n",
    "import pandas as pd\n",
    "\n",
    "train_path = './essay_dataset/training_set_rel3.tsv'\n",
    "training_data = load_training_set(train_path)\n",
    "\n",
    "glove_dict = load_dict('glove.840B.300d.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path = './essay_dataset/valid_set.tsv'\n",
    "valid_label_path = './essay_dataset/valid_sample_submission_2_column.csv'\n",
    "valid_data = load_validation_set(valid_path, valid_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = process_scores(training_data, 'domain1_score')\n",
    "valid_data = process_scores(valid_data, 'domain1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import cfg\n",
    "\n",
    "cfg['input_dim'] = 301 # input dimension to LSTM\n",
    "cfg['hidden_dim'] = 256 # hidden dimension for LSTM\n",
    "cfg['output_dim'] = 1 # output dimension of the model\n",
    "cfg['layers'] = 2 # number of layers of LSTM\n",
    "\n",
    "cfg['dropout'] = 0.005 # dropout rate between two layers of LSTM; useful only when layers > 1; between 0 and 1\n",
    "cfg['bidirectional'] = True # True or False; True means using a bidirectional LSTM\n",
    "cfg['batch_size'] = 120 # batch size of input\n",
    "cfg['learning_rate'] = 2e-4 # learning rate to be used\n",
    "cfg['L2_penalty'] = 1e-5 # weighting constant for L2 regularization term; this is a parameter when you define optimizer\n",
    "cfg['epochs'] = 20 # number of epochs for which the model is trained\n",
    "cfg['embed'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "from dataloader import *\n",
    "from models import *\n",
    "import time\n",
    "\n",
    "model = LSTM_Score(cfg, True)\n",
    "model = model.to(torch.device(cfg['device']))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=cfg['learning_rate'], weight_decay=cfg['L2_penalty'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['learning_rate'], weight_decay=cfg['L2_penalty'])\n",
    "\n",
    "train_indices = list(range(len(training_data)))\n",
    "valid_indices = list(range(len(valid_data)))\n",
    "\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Score(\n",
       "  (embed_linear): Linear(in_features=301, out_features=301, bias=True)\n",
       "  (lstm): LSTM(301, 256, num_layers=2, batch_first=True, dropout=0.005, bidirectional=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc1_normed): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2_normed): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 20, loss = 38.12351\n",
      "count = 40, loss = 36.02974\n",
      "count = 60, loss = 36.76304\n",
      "count = 80, loss = 33.82230\n",
      "count = 100, loss = 33.43119\n",
      "count = 120, loss = 33.67876\n",
      "validation loss: 33.40795489719936\n",
      "epoch finished: 1\n",
      "count = 20, loss = 33.15570\n",
      "count = 40, loss = 32.06822\n",
      "count = 60, loss = 31.04934\n",
      "count = 80, loss = 29.40777\n",
      "count = 100, loss = 30.45158\n",
      "count = 120, loss = 30.18026\n",
      "validation loss: 29.510453996204195\n",
      "epoch finished: 2\n",
      "count = 20, loss = 29.15325\n",
      "count = 40, loss = 28.25833\n",
      "count = 60, loss = 26.59201\n",
      "count = 80, loss = 27.76823\n",
      "count = 100, loss = 26.35131\n",
      "count = 120, loss = 24.97263\n",
      "validation loss: 25.557173138573056\n",
      "epoch finished: 3\n",
      "count = 20, loss = 24.78251\n",
      "count = 40, loss = 24.36291\n",
      "count = 60, loss = 24.34687\n",
      "count = 80, loss = 24.25803\n",
      "count = 100, loss = 22.63428\n",
      "count = 120, loss = 22.20809\n",
      "validation loss: 22.257712682088215\n",
      "epoch finished: 4\n",
      "count = 20, loss = 21.91467\n",
      "count = 40, loss = 20.76736\n",
      "count = 60, loss = 20.40060\n",
      "count = 80, loss = 18.99307\n",
      "count = 100, loss = 20.52974\n",
      "count = 120, loss = 19.91275\n",
      "validation loss: 18.93641839708601\n",
      "epoch finished: 5\n",
      "count = 20, loss = 18.38377\n",
      "count = 40, loss = 18.17946\n",
      "count = 60, loss = 18.27347\n",
      "count = 80, loss = 17.31682\n",
      "count = 100, loss = 17.00304\n",
      "count = 120, loss = 16.00307\n",
      "validation loss: 16.117327849070232\n",
      "epoch finished: 6\n",
      "count = 20, loss = 16.11737\n",
      "count = 40, loss = 15.45791\n",
      "count = 60, loss = 15.65819\n",
      "count = 80, loss = 14.31467\n",
      "count = 100, loss = 13.62580\n",
      "count = 120, loss = 13.56399\n",
      "validation loss: 13.469082151140485\n",
      "epoch finished: 7\n",
      "count = 20, loss = 12.89637\n",
      "count = 40, loss = 12.65669\n",
      "count = 60, loss = 12.83093\n",
      "count = 80, loss = 12.58184\n",
      "count = 100, loss = 11.85478\n",
      "count = 120, loss = 11.72690\n",
      "validation loss: 11.026338577270508\n",
      "epoch finished: 8\n",
      "count = 20, loss = 10.93041\n",
      "count = 40, loss = 10.57844\n",
      "count = 60, loss = 10.23534\n",
      "count = 80, loss = 10.88699\n",
      "count = 100, loss = 9.91608\n",
      "count = 120, loss = 10.00598\n",
      "validation loss: 9.202618598937988\n",
      "epoch finished: 9\n",
      "count = 20, loss = 9.22989\n",
      "count = 40, loss = 9.28828\n",
      "count = 60, loss = 9.00575\n",
      "count = 80, loss = 8.67816\n",
      "count = 100, loss = 8.62168\n",
      "count = 120, loss = 7.81695\n",
      "validation loss: 7.732690481912522\n",
      "epoch finished: 10\n",
      "count = 20, loss = 7.74109\n",
      "count = 40, loss = 7.69901\n",
      "count = 60, loss = 7.82175\n",
      "count = 80, loss = 7.71175\n",
      "count = 100, loss = 7.58543\n",
      "count = 120, loss = 7.22935\n",
      "validation loss: 6.594554991949172\n",
      "epoch finished: 11\n",
      "count = 20, loss = 6.96014\n",
      "count = 40, loss = 6.66510\n",
      "count = 60, loss = 6.52130\n",
      "count = 80, loss = 6.61814\n",
      "count = 100, loss = 6.82398\n",
      "count = 120, loss = 6.72022\n",
      "validation loss: 5.838234958194551\n",
      "epoch finished: 12\n",
      "count = 20, loss = 5.97686\n",
      "count = 40, loss = 6.50487\n",
      "count = 60, loss = 6.16358\n",
      "count = 80, loss = 6.41119\n",
      "count = 100, loss = 6.19907\n",
      "count = 120, loss = 5.91708\n",
      "validation loss: 5.330456256866455\n",
      "epoch finished: 13\n",
      "count = 20, loss = 5.79236\n",
      "count = 40, loss = 5.75908\n",
      "count = 60, loss = 6.23103\n",
      "count = 80, loss = 5.88574\n",
      "count = 100, loss = 5.72432\n",
      "count = 120, loss = 5.84769\n",
      "validation loss: 5.050125911122277\n",
      "epoch finished: 14\n",
      "count = 20, loss = 5.56398\n",
      "count = 40, loss = 5.95352\n",
      "count = 60, loss = 5.60097\n",
      "count = 80, loss = 5.74387\n",
      "count = 100, loss = 5.50711\n",
      "count = 120, loss = 5.77029\n",
      "validation loss: 4.922242295174372\n",
      "epoch finished: 15\n",
      "count = 20, loss = 5.58953\n",
      "count = 40, loss = 5.64343\n",
      "count = 60, loss = 5.72991\n",
      "count = 80, loss = 5.55834\n",
      "count = 100, loss = 5.55318\n",
      "count = 120, loss = 5.55632\n",
      "validation loss: 4.78782396089463\n",
      "epoch finished: 16\n",
      "count = 20, loss = 5.24764\n",
      "count = 40, loss = 5.47720\n",
      "count = 60, loss = 5.70741\n",
      "count = 80, loss = 5.83441\n",
      "count = 100, loss = 5.56963\n",
      "count = 120, loss = 5.34596\n",
      "validation loss: 4.741502574511936\n",
      "epoch finished: 17\n",
      "count = 20, loss = 5.46630\n",
      "count = 40, loss = 5.37792\n",
      "count = 60, loss = 5.68927\n",
      "count = 80, loss = 5.47112\n",
      "count = 100, loss = 5.73253\n",
      "count = 120, loss = 5.43790\n",
      "validation loss: 4.715214587393261\n",
      "epoch finished: 18\n",
      "count = 20, loss = 5.51476\n",
      "count = 40, loss = 5.36517\n",
      "count = 60, loss = 5.40482\n",
      "count = 80, loss = 5.46123\n",
      "count = 100, loss = 5.88805\n",
      "count = 120, loss = 5.42993\n",
      "validation loss: 4.688049668357486\n",
      "epoch finished: 19\n",
      "count = 20, loss = 5.46195\n",
      "count = 40, loss = 5.37565\n",
      "count = 60, loss = 5.24664\n",
      "count = 80, loss = 5.70046\n",
      "count = 100, loss = 5.65785\n",
      "count = 120, loss = 5.46962\n"
     ]
    }
   ],
   "source": [
    " for epoch in range(cfg['epochs']):\n",
    "    tloader = DataLoader(training_data, train_indices, cfg, glove_dict)\n",
    "    vloader = DataLoader(valid_data, valid_indices, cfg, glove_dict)\n",
    "    \n",
    "    count = 0\n",
    "    avg_loss = 0\n",
    "    while tloader.has_next():\n",
    "        train, label = tloader.get_next()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        y = model(train)\n",
    "        \n",
    "        \n",
    "        loss = criterion(y, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        avg_loss += loss.item()\n",
    "        if count % 20 == 0:\n",
    "            print(\"count = %d, loss = %.5f\" %(count, avg_loss / 20))\n",
    "            save_model(model, 'models_score/e' + str(epoch + 1) + 'b' + str(count) + '.pt')\n",
    "            avg_loss = 0\n",
    "        del train, label, y, loss\n",
    "    \n",
    "    count = 0\n",
    "    avg_loss = 0\n",
    "    with torch.no_grad():\n",
    "        while vloader.has_next():\n",
    "            train, label = vloader.get_next()\n",
    "            y = model(train)\n",
    "            loss = criterion(y, label)\n",
    "            count += 1\n",
    "            avg_loss += loss.item()\n",
    "            del train, label, y, loss\n",
    "    print('validation loss:', avg_loss / count)\n",
    "    print('epoch finished:', epoch + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4420],\n",
      "        [-2.5168],\n",
      "        [ 1.9238],\n",
      "        [-0.3252],\n",
      "        [ 0.7334]], device='cuda:0')\n",
      "validation loss: 4.505162239074707\n"
     ]
    }
   ],
   "source": [
    "cfg['batch_size'] = 5\n",
    "vloader = DataLoader(valid_data, valid_indices, cfg, glove_dict)\n",
    "count = 0\n",
    "avg_loss = 0\n",
    "with torch.no_grad():\n",
    "    while vloader.has_next():\n",
    "        train, label = vloader.get_next()\n",
    "        y = model(train)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "        print(label - y)\n",
    "        loss = criterion(y, label)\n",
    "        count += 1\n",
    "        avg_loss += loss.item()\n",
    "        del train, label, y, loss\n",
    "        break\n",
    "print('validation loss:', avg_loss / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-955b5d25e5d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
